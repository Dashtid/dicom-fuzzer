name: CI Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -r requirements.txt
          uv pip install -e .

      - name: Check code formatting with black
        run: |
          source .venv/bin/activate
          black --check .

      - name: Check import sorting with isort
        run: |
          source .venv/bin/activate
          isort --check-only .

      - name: Lint with flake8
        run: |
          source .venv/bin/activate
          flake8 . --count --show-source --statistics --extend-ignore=E203

  security-scan:
    name: Security Scanning
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -r requirements.txt
          uv pip install -e .
          uv pip install bandit[toml] safety

      - name: Run bandit security scanner
        run: |
          source .venv/bin/activate
          bandit -r core/ strategies/ utils/ -f json -o bandit-report.json || true
          bandit -r core/ strategies/ utils/ --severity-level medium

      - name: Check for known vulnerabilities with safety
        run: |
          source .venv/bin/activate
          safety check --json || true
          safety check

      - name: Check dependencies with pip-audit
        run: |
          source .venv/bin/activate
          uv pip install pip-audit
          pip-audit --desc --format json -o pip-audit-report.json || true
          # Continue even if vulnerabilities found (for informational purposes)
          pip-audit --desc || echo "Vulnerabilities found - review pip-audit-report.json"

      - name: Run semgrep security analysis
        run: |
          uv pip install semgrep
          source .venv/bin/activate
          semgrep --config=auto --json --output=semgrep-report.json . || true
          # Continue even if issues found
          semgrep --config=auto . || echo "Security issues found - review semgrep-report.json"

      - name: Upload bandit results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: bandit-report
          path: bandit-report.json

      - name: Upload pip-audit results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pip-audit-report
          path: pip-audit-report.json

      - name: Upload semgrep results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: semgrep-report
          path: semgrep-report.json

  test:
    name: Test Suite (Python ${{ matrix.python-version }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ['3.11', '3.12', '3.13']

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install uv (Linux/macOS)
        if: runner.os != 'Windows'
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install uv (Windows)
        if: runner.os == 'Windows'
        run: |
          irm https://astral.sh/uv/install.ps1 | iex
          echo "$env:USERPROFILE\.cargo\bin" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append

      - name: Install dependencies (Linux/macOS)
        if: runner.os != 'Windows'
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -r requirements.txt
          uv pip install -e .

      - name: Install dependencies (Windows)
        if: runner.os == 'Windows'
        run: |
          uv venv
          .venv\Scripts\activate
          uv pip install -r requirements.txt
          uv pip install -e .

      - name: Run tests with coverage (Linux/macOS)
        if: runner.os != 'Windows'
        run: |
          source .venv/bin/activate
          pytest tests/ -v --cov=. --cov-report=xml --cov-report=html --cov-report=term

      - name: Run tests with coverage (Windows)
        if: runner.os == 'Windows'
        run: |
          .venv\Scripts\activate
          pytest tests/ -v --cov=. --cov-report=xml --cov-report=html --cov-report=term

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        with:
          name: coverage-report
          path: htmlcov/

      - name: Check coverage threshold
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
        run: |
          source .venv/bin/activate
          # Threshold set to 90% - Production code has 95%+ coverage
          # Framework modules (not yet integrated) excluded via pyproject.toml
          coverage report --fail-under=90

  performance-benchmark:
    name: Performance Benchmarking
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -r requirements.txt
          uv pip install -e .
          uv pip install pytest-benchmark

      - name: Run performance benchmarks
        run: |
          source .venv/bin/activate
          pytest tests/ -v --benchmark-only --benchmark-json=benchmark-report.json || true

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-report
          path: benchmark-report.json

  mutation-testing:
    name: Mutation Testing
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -r requirements.txt
          uv pip install -e .
          uv pip install mutmut

      - name: Run mutation testing
        run: |
          source .venv/bin/activate
          # mutmut command syntax - run mutations on all Python files
          mutmut run || true
          mutmut results || echo "No mutation results yet"
          mutmut html || echo "HTML report generation skipped"

      - name: Upload mutation testing results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mutation-report
          path: html/

  documentation-build:
    name: Documentation Build Verification
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install -r requirements.txt
          uv pip install -e .
          cd docs && uv pip install -r requirements.txt

      - name: Build Sphinx documentation
        run: |
          source .venv/bin/activate
          cd docs
          make clean
          make html SPHINXOPTS="-W --keep-going"

      - name: Check documentation links
        run: |
          source .venv/bin/activate
          cd docs
          make linkcheck

      - name: Upload documentation
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: docs/_build/html/

  build-status:
    name: Build Status Summary
    runs-on: ubuntu-latest
    needs: [code-quality, security-scan, test, performance-benchmark, documentation-build]
    if: always()
    steps:
      - name: Check build status
        run: |
          if [ "${{ needs.code-quality.result }}" != "success" ]; then
            echo "Code quality checks failed"
            exit 1
          fi
          if [ "${{ needs.security-scan.result }}" != "success" ]; then
            echo "Security scan failed"
            exit 1
          fi
          if [ "${{ needs.test.result }}" != "success" ]; then
            echo "Tests failed"
            exit 1
          fi
          if [ "${{ needs.performance-benchmark.result }}" != "success" ]; then
            echo "Performance benchmarks failed"
            exit 1
          fi
          if [ "${{ needs.documentation-build.result }}" != "success" ]; then
            echo "Documentation build failed"
            exit 1
          fi
          echo "All checks passed successfully!"
